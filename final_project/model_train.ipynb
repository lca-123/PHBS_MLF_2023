{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75e0de97f8c4a412"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:19:48.675067Z",
     "start_time": "2024-04-11T06:19:47.335012Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from code.train_model import ModelTrainer\n",
    "from code.function import load_train_data, load_test_data\n",
    "\n",
    "from model.gru_base import GRUModel\n",
    "from model.gru_patch import GRUPatchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load data\n",
    "\n",
    "load the processed data and split the train set, test set and valid set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e55ede675035767"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5272, 2498, 6) (5272, 2498) (5272, 2498) (2498,) (5272,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('data/processed_data/X.npy')\n",
    "ret5 = np.load('data/processed_data/ret5.npy')\n",
    "ret10 = np.load('data/processed_data/ret10.npy')\n",
    "\n",
    "sample_datetime = np.load('data/processed_data/sample_datetime.npy', allow_pickle=True)\n",
    "sample_stock = np.load('data/processed_data/sample_stock.npy', allow_pickle=True)\n",
    "print(X.shape, ret5.shape, ret10.shape, sample_datetime.shape, sample_stock.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:19:48.921411Z",
     "start_time": "2024-04-11T06:19:48.675980Z"
    }
   },
   "id": "762f749d0e5f42ea",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5272, 2248, 6) (5272, 2248) (2248,)\n",
      "(5272, 290, 6) (5272, 290) (250,)\n"
     ]
    }
   ],
   "source": [
    "train_end = int(len(sample_datetime) * 0.9)\n",
    "valid_end = int(len(sample_datetime))\n",
    "\n",
    "seq_len = 40\n",
    "\n",
    "X_train, X_valid = X[:, :train_end], X[:, train_end-seq_len:valid_end]\n",
    "y_train, y_valid = ret10[:, :train_end], ret10[:, train_end-seq_len:valid_end]\n",
    "train_date, valid_date = sample_datetime[:train_end], sample_datetime[train_end:valid_end]\n",
    "\n",
    "print(X_train.shape, y_train.shape, train_date.shape)\n",
    "print(X_valid.shape, y_valid.shape, valid_date.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:19:48.925654Z",
     "start_time": "2024-04-11T06:19:48.923085Z"
    }
   },
   "id": "bc22f4f6334c620",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x1_train, x1_test, y_train, y_test = load_train_data(X_train, y_train)\n",
    "BATCH_SIZE = 5000\n",
    "\n",
    "class Newdataset(Dataset):\n",
    "    def __init__(self, data1, label) -> None:\n",
    "        super().__init__()\n",
    "        self.data1 = data1.astype(np.float32)\n",
    "        self.label = label.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data1[index], self.label[index]\n",
    "\n",
    "train_ds = Newdataset(x1_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_ds = Newdataset(x1_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:20:01.426479Z",
     "start_time": "2024-04-11T06:19:48.926926Z"
    }
   },
   "id": "cd1bf303bb79e8ba",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## set model\n",
    "\n",
    "set up the model trainer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95a5d707b29f5a35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model1 = GRUModel()\n",
    "model2 = GRUPatchModel()\n",
    "\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.005)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.005)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "modeltrainer1 = ModelTrainer(model1, optimizer1, device, 'gru')\n",
    "modeltrainer2 = ModelTrainer(model2, optimizer2, device, 'gru_patch')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:20:01.883200Z",
     "start_time": "2024-04-11T06:20:01.428065Z"
    }
   },
   "id": "67a821a7eae1379b",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "train model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ae3c2e6c738ac89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# modeltrainer1.fit(train_dl, test_dl, 'data')\n",
    "# modeltrainer2.fit(train_dl, test_dl, 'data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:20:01.885154Z",
     "start_time": "2024-04-11T06:20:01.883957Z"
    }
   },
   "id": "95e42f278cc5ed03",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## predict factor\n",
    "\n",
    "use the model in valid set and get the factor output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcc02ea2f49ad0b3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load model\n",
    "model1 = torch.load('data/saved_model/gru.pt')\n",
    "model2 = torch.load('data/saved_model/gru_patch.pt')\n",
    "\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.005)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.005)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "modeltrainer1 = ModelTrainer(model1, optimizer1, device, 'gru')\n",
    "modeltrainer2 = ModelTrainer(model2, optimizer2, device, 'gru_patch')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:20:01.892788Z",
     "start_time": "2024-04-11T06:20:01.885868Z"
    }
   },
   "id": "a437c1fa312ab8f4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict_valid_set(X_valid, y_valid, modeltrainer, valid_date, sample_stock):\n",
    "    fac_1 = pd.DataFrame(np.nan * np.zeros((X_valid.shape[0], len(valid_date)-10)))\n",
    "    i_panel = 0\n",
    "    for i in tqdm(range(len(valid_date)-10)):\n",
    "        x1_test, y_test, nonan_index = load_test_data(X_valid[:, i:i+seq_len, :], y_valid[:, i:i+seq_len])\n",
    "        test_ds = Newdataset(x1_test, y_test)\n",
    "        test_dl = DataLoader(test_ds, batch_size=len(x1_test))\n",
    "\n",
    "        y_pred = modeltrainer.predict(test_dl)\n",
    "        fac_1.iloc[nonan_index, i_panel] = y_pred[:, -1]\n",
    "        i_panel += 1\n",
    "    fac_1.columns = valid_date[:i_panel]\n",
    "    fac_1.index = sample_stock\n",
    "    return fac_1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:20:01.895463Z",
     "start_time": "2024-04-11T06:20:01.893412Z"
    }
   },
   "id": "508938188e4c272f",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:36<00:00,  6.57it/s]\n",
      "100%|██████████| 240/240 [01:47<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "fac1 = predict_valid_set(X_valid, y_valid, modeltrainer1, valid_date, sample_stock)\n",
    "fac2 = predict_valid_set(X_valid, y_valid, modeltrainer2, valid_date, sample_stock)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:22:26.182383Z",
     "start_time": "2024-04-11T06:20:01.897143Z"
    }
   },
   "id": "98136feff8c40385",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fac1.to_csv('data/saved_factor/fac1.csv')\n",
    "fac2.to_csv('data/saved_factor/fac2.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T06:23:12.799740Z",
     "start_time": "2024-04-11T06:23:11.472971Z"
    }
   },
   "id": "6bfc42564765436e",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
